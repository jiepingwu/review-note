### 日志和索引相关问题

#### redo log 和 bin log 的双阶段提交（日志相关）

​	前面我们知道了 在一条 update 中，redo log 和 bin log 是基于redo log的双阶段提交，用于保证 bin log 和 redo log 的数据一致性。

​	我们先来分析一下，**在双阶段提交的不同时刻，MySQL异常重启会出现什么情况。**

![image-20210605191721349](..\references-figures\image-20210605191721349.png)

​	以上图update过程为例：

1. **如果在时刻A，**也就是写入 redo log prepare阶段后，写入 bin log 之前的时候发生了 崩溃(crash)，由于这个时候bin log还没写，redo log也还没有提交，所以 崩溃恢复的时候，这个事务会被回滚，也就说 redo log prepare中的记录不会被redo，而 bin log 也没有写，所以传入备份库中。
2. **如果在时刻B，**也就是写入 redo log prepare阶段后，写入 bin log 之后，发生了 crash，这个时候 redo log 处于prepare阶段，这个时候的 crash 恢复判断规则是这样的：如果 redo log 是处于 commit 阶段，则直接提交；如果 redo log 处于 prepare 阶段，则需要判断 bin log 是否存在，如果存在，则提交redo log，保证两者数据一致性，如果不存在，则进行事务回滚。



我们来拓展一下这个问题：

**追问1：MySQL怎么知道 bin log 是完整的？**

Answer：一个事务的 bin log 是有完整的格式的：

- statement 格式的 bin log，最后会有 COMMIT；
- row 格式的 bin log，最后会有一个 XID event。

另外，在 MySQL 5.6.2 版本后，还引入了 binlog-checksum 参数，用于验证 bin log 内容的正确性。对于 bin log 日志由于磁盘原因，可能在日志中间出错的情况，MySQL 可以通过 checksum 的结果来发现。所以，MySQL还是有办法验证事务 bin log 的完整性的。



**追问2：redo log 和 bin log 是怎么关联起来的？**

Answer：由于要对两个log中的数据进行同步，所以我们需要知道redo log 和 bin log 的对应。那么它们是怎么关联的？

它们有一个共同的数据字段，叫 XID。crash 恢复的时候，会顺序扫描 redo log：

- 如果碰到既有 prepare，又有 commit 的 redo log，就直接提交。
- 如果碰到只有 prepare，没有 commit 的 redo log，就需要根据 XID 在 bin log 中查找对应的事务 的 bin log 是否完整，向上面说的，不完整则回滚redo log，完整则提交 redo log。



**追问3：处于 prepare 阶段的 redo log 加上完整 bin log，重启后就能恢复，MySQL为什么要这么设计？**

Answer：还是为了保证数据和备份的一致性。在上面的时刻B，也就是 bin log 提交 但是 redo log 处于 prepare 阶段是，如果发生 crash，这个时候 bin log 已经写入了，之后使用bin log的时候就可能导致数据不一致。所以，在当前数据库中也要提交这个事务，这样，保证比如 主库和从库(使用bin log)的数据一致性。



**追问4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 bin log，而在 crash 恢复的时候，必须两个日志都完整才可以，不是也行吗？**

Answer：其实，我们首先要知道，两阶段提交不是MySQL特有的，它是解决 分布式系统的数据一致性 的一种解决方案。也就是说，我们这里的 redo  log 和 bin log 其实可以看成是 两个分布式系统，由于 redo log 是 innodb引擎层存储的，而 bin log 是 Server 层存储，所以我们可以使用 双阶段提交保证这两个系统的数据一致性。

另外，对于 innodb 来说，如果 redo log 提交了，那么就不能回滚了，而如果 redo log 提交 但是 bin log 写入失败，却不能回滚 redo log，那么数据就和 bin log 不一致了。



**追问5：不引入 redo log，也就没有双阶段提交的必要了，也就是说，我们只使用 bin log 来支持 safe crash，而且能支持归档，不行吗？**

Answer：答案是不可以。

1. 考虑历史原因的话：那就是 innodb 并不是 MySQL 的原生存储引擎，MySQL 的原生引擎是 MyISAM，而这个引擎原生就不支持 safe crash。而在 innodb 接入了 MySQL 之后，发现既然 bin log 没有 safe crash 的能力，那就用 innodb 中支持safe crash的 redo log 好了。
2. 考虑实现原因的话：只使用 bin log 并不能实现 safe crash的能力，因为 bin log 并不能完全的代替 redo log。由于 innodb 使用的是 WAL，也就是说需要使用 redo log 重放刷盘，而如果只有 bin log 的话，在 crash 的时候，就不能实现重放刷新数据页了。所以，如果要完全实现只使用 bin log 完成 safe crash，那么就需要将 bin log 和 redo log 的功能完全整合，需要重写 bin log 的功能，而至少现在的 bin log 做不到。



**追问6：那能不能反过来，只用 redo log，不要 bin log？**

Answer：如果只考虑 safe crash 的话，是可以的，关掉 bin log ，这样就没有 双阶段提交了，系统依然是 crash-safe 的。

但是 bin log 有它自己独特的功能：

1. 归档：bin log 能完成归档，备份数据库的能力，而 redo log 做不到，因为 redo log 是 循环写的。
2. MySQL系统依赖于 bin log，bin log 是 MySQL 系统高可用的基础。



**追问7：redo log 一般设置多大？**

Answer：redo log 太小的话，会很快被写满，然后不得不进行 刷盘，这样 WAL 机制的能力就发挥不出来。

所以，如果是常见的几个TB的磁盘的话，就不要太小了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。



**追问8：正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新的 还是从 buffer pool 更新的呢？**

Answer：这其实是在问"redo log 中保存的到底是什么?"。redo log 实际上不会记录数据，而是记录哪个数据页上做了什么修改，那么就不可能可以从 redo log 中直接落盘。

对于正常运行的实例来说：如果存在脏页，刷盘的时候，是将内存中的数据更新到磁盘，这个过程和 redo log 没有关系。

对于crash-safe场景来说：如果innodb判断一个数据页需要使用 redo log 重放，就会将它读入到内存中，然后使用redo log更新数据，再将内存中数据刷入磁盘，也就是上面那种情况。

所以，数据写入的落盘过程中，本质上就是从内存buffer pool中将数据更新到磁盘上，而 redo log 只是在 crash 的时候重放，用于WAL，保证数据一致性，懒写盘减少磁盘写IO。



**追问9：redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？**

Answer：这两个问题可以一起回答：

在一个事务的更新过程中，日志也是多阶段写入的，比如下面这个事务：

```sql
begin;
insert into t1 ...
insert into t2 ...
commit;
```

这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但是又不能在还没有 commit 的时候就 直接写入到 redo log 中。

所以，redo log buffer 就是一块用于缓存马上要被写入 redo log 的数据的内存。也就是说 事务中的一条更新 就将一个 log 记录到 redo log buffer 中，同时 内存中数据也会被修改。但是真正将 log 记录到 redo log，则是在 commit 之后。



#### 业务设计问题（索引相关）

现在有这样一个场景：A和B两个用户，如果相互关注，则成为好友。

设计上，有两张表，一张是 like 表，一张是 friend 表，like 表有 user_id，liker_id 两个字段，联合唯一索引uk_user_id_liker_id。

执行逻辑：

以A关注B为例：

1. 查询对方有没有关注自己（即 B 有没有关注 A）

**select * from like where user_id = B and liker_id = A;**

2. 如果有，则成为好友：**insert into friend;**
3. 如果没有，则只是单向关注：**insert into like;**

但是，在并发情况下，如果 A 和 B 同时关注对方，则会出现不会成为好友的情况。

因为，这种情况下第1步，两者都没有被对方关注，则就会将双方都 insert into like，而不会成为好友。

**这种情况，该怎么解决？**



![image-20210605213319363](..\references-figures\image-20210605213319363.png)

两个事务的执行过程如上。

可以发现，问题的关键在于：比如session 1中不能保证 select 和 insert 的原子性，也就说不能保证 查询 B 是否关注了 A，如果没有则 插入 like 其中 A like B。而由于 没有行数据，这里 select 不能使用行锁。

我们来看这个逻辑：如果 B 没有关注 A，则将 A 关注 B 插入 like 表。如果有，则将 A B 插入 friend 表。我们怎样将上面的select and insert 变为一个原子操作，既然 没有数据不能用行锁，我们就先插入数据。为此，我们需要在 like 表中记录所有的 like 情况(而不是像上面这样，只记录了 A like B 或者 B like A，还要记录 A like and B like A)，并且如果表中存在 like 关系，则更新like关系。

于是，**我们改造 like 表结构，加入 relation_ship 字段，字段值 1, 2, 3，并且保证 liker1_id < liker2_id，即AlikeB在表中的时候为 A_id < B_id。**

**relation_ship = 1：表示 A like B；relation_ship = 2：表示 B like A；relation_ship = 3 表示 A like B and B like A。**

然后，当 A 关注 B 时：（A < B时）

```sql
mysql> begin;
insert into 'like'(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;
select relation_ship from 'like' where user_id=A and liker_id=B;
	如果 relation_ship = 1，事务结束，执行commit
	如果 relation_ship = 3，则执行下面的两个语句：
insert ignore into friend(friend_1_id, friend_2_id) values (A, B);
commit;
```

（A > B 时）

```sql

mysql> begin; /*启动事务*/
insert into 'like'(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;
select relation_ship from `like` where user_id=B and liker_id=A;
/*代码中判断返回的 relation_ship，
  如果是2，事务结束，执行 commit
  如果是3，则执行下面这两个语句：
*/
insert ignore into friend(friend_1_id, friend_2_id) values(B,A);
commit;
```

注意：

1. 使用 on duplicate 开启行锁，保证下面的select relation_ship被行数保护。
2. on duplicate key update relation_ship = relation_ship | 1 ，在主键已经存在，即 A like B 或者 B like A 或 A like B and B like A 存在时，| 按位或运算巧妙地更新了 like 关系。