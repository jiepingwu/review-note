### HTTP 2 优化在哪里？

##### HTTP1.1的问题

HTTP1.1的问题在于 高延迟。

- 并发连接有限 ：Google chrome 最大并发连接数为 6个，并且每次都要经过 TCP 和 TLS 握手。
- 队头阻塞问题：同一个连接只能在完成一个HTTP事务(请求和响应)后，才能处理下一个事务。
- HTTP 头部巨大并且重复：由于HTTP协议是无状态的，所以每一个请求都需要携带HTTP头部，特别对于携带cookie的头部，cookie的大小通常很大。
- 不支持服务器推送：当客户端需要获取通知时，只能通过定时器不断地从服务器拉去消息，这浪费了大量的带宽和服务器资源。

为了解决HTTP1.1的性能问题，可以从以下方面考虑：(*<u>2.2 HTTP1.1如何进行优化</u>* 中写过)

1. 尽可能地避免HTTP连接，将需要的频繁数据进行本地缓存。
2. 减少HTTP连接次数，
    1. 将原本由服务端处理的重定向交给代理服务器进行，减少重定向请求。
    2. 将大量小文件，大量小图片，打包为 大文件 进行传输。
    3. 将多个体积较小的JavaScript文件使用 webpack 等工具打包为一个大 JS 文件。
3. 压缩响应资源

而上面这些方法都是外部的优化手段，而要根本地解决 HTTP 1.1 的问题，要进行内部优化，比如 请求-响应模型，头部巨大且重复，并发连接耗时，服务器不能主动推送等，这些改变需要重新设计 HTTP 协议，即成为 HTTP 2。



1. **头部压缩**

对于常见的 HTTP 头部通过 静态表 和 Huffman 编码的方式，压缩体积，而且针对后续的请求头部，还可以建立 动态表，将体积压缩将近90%，提高编码效率，同时节约了带宽资源。

HTTP2没有使用常见的 gzip压缩方式来压缩header，而是开发了 HPACK 算法，HPACK 算法由 3 个部分组成：

- 静态字典
- 动态字典
- Huffman 编码(压缩为二进制的算法)

具体来说，服务端和客户端都会建立和维护 一个字典，使用长度较小的索引号来表示重复的字符串，再用huffman编码压缩为二进制。该字典可以是静态的，也可以是传输过程中动态更新的。

2 **Stream并发传输**

实现类 Stream并发，多个 Stream只需要复用1个TCP连接，节约了TCP和TLS握手时间。

每个Stream中存放多个Message，Message中有多个数据帧frame，每个frame都有一个Stream ID，于是Stream可以乱序发送，接收方根据StreamID拼接，但是同一个Stream里的frame必须严格有序。

3 **服务端主动推送**

服务器推送资源时，先发送 PUSH_PROMISE frame 告知客户端在哪个 Stream中发送资源，然后将资源使用偶数号Stream发送给客户端。



但是，HTTP2还不完美，因为，虽然解决了 HTTP1中的队头阻塞问题，但是，在 TCP 层面，依然存在。

基于TCP协议传输数据，TCP层需要保证所有收到的字节流是完整且连续的，这样内核才会将缓冲区中的数据返回给HTTP应用，所以，只要数据没有完整，那么就会存放在内核缓冲区中，只有完整了，HTTP应用层才能从内核中拿到数据，依然是一种 HTTP2的队头阻塞。

那么，HTTP3就抛弃了 TCP，而使用 基于 QUIC 的 UDP 协议来实现。